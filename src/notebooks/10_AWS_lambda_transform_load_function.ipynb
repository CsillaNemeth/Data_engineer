{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2247cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "\n",
    "def transform_weather_data(weather_data) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transforms raw weather data into a pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    weather_data : dict\n",
    "        A dictionary containing weather information with a structure that includes \n",
    "        'hourly' data for 'time', 'temperature_2m', 'wind_speed_10m', 'rain', and 'precipitation'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with the following columns:\n",
    "        - 'datetime': Converted to pandas datetime format\n",
    "        - 'temperature': Temperature at 2 meters\n",
    "        - 'wind_speed': Wind speed at 10 meters\n",
    "        - 'rain': Rain amount\n",
    "        - 'precipitation': Precipitation amount\n",
    "    \"\"\"\n",
    "    weather_data_filtered = {\n",
    "        'datetime': weather_data['hourly'][\"time\"],\n",
    "        'tempereature': weather_data['hourly']['temperature_2m'],\n",
    "        'wind_speed': weather_data['hourly']['wind_speed_10m'],\n",
    "        'rain': weather_data['hourly']['rain'],\n",
    "        'precipitation': weather_data['hourly']['precipitation']\n",
    "    }\n",
    "\n",
    "    weather_df = pd.DataFrame(weather_data_filtered)\n",
    "    weather_df['datetime'] = pd.to_datetime(weather_df['datetime'])\n",
    "\n",
    "  \n",
    "    return weather_df\n",
    "\n",
    "def taxi_trips_transformation(taxi_trips: pd.DataFrame) -> pd.DataFrame:\n",
    "    ''' \n",
    "    Transforms the taxi trips DataFrame\n",
    "\n",
    "    Parameters:\n",
    "        taxi_trips (pd.DataFrame): A DataFrame containing taxi trip data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The transformed DataFrame with the specified columns removed, renamed, \n",
    "                      and a new 'datetime_for_weather' column added.\n",
    "    '''\n",
    "    if not isinstance(taxi_trips, pd.DataFrame):\n",
    "        raise ('taxi_trips is not a valid pandas DataFrame')\n",
    "\n",
    "    taxi_trips.drop(['pickup_census_tract', 'dropoff_census_tract', 'pickup_centroid_location', 'dropoff_centroid_location'], axis=1, inplace=True)\n",
    "    \n",
    "    taxi_trips.dropna(inplace=True)\n",
    "    \n",
    "    taxi_trips.rename(columns={'pickup_community_area': 'pickup_community_area_id', 'dropoff_community_area': 'dropoff_community_area_id'}, inplace=True)\n",
    "    \n",
    "    taxi_trips['datetime_for_weather'] = pd.to_datetime(taxi_trips['trip_start_timestamp']).dt.floor('h')\n",
    "    \n",
    "    return taxi_trips\n",
    "\n",
    "def update_master(taxi_trips: pd.DataFrame, master: pd.DataFrame, id_column: str, value_column: str ) -> pd.DataFrame:\n",
    "    \"\"\"Extend the master DataFrame with new items if there are any.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    taxi_trips : pd.DataFrame\n",
    "        DataFrame holding the daily taxi trips.\n",
    "    master: pd.DataFrame\n",
    "        DataFrame holding master data.\n",
    "    id_column: srt\n",
    "        Id of the...\n",
    "    value_column: str\n",
    "        Value of the master DataFrame.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The updated payment_type_master data, if new payment types are in the taxi data, they will be loaded to it.\n",
    "    \"\"\"\n",
    "\n",
    "    max_id = master[id_column].max()\n",
    "\n",
    "    new_value_list = [value for value in taxi_trips[value_column].values if value not in master[value_column].values]\n",
    "    new_value_df = pd.DataFrame({\n",
    "        id_column: range(max_id + 1, max_id + len(new_value_list) + 1),\n",
    "        value_column: new_value_list\n",
    "    })\n",
    "    \n",
    "    updated_master = pd.concat([master, new_value_df], ignore_index=True)\n",
    "\n",
    "    return updated_master\n",
    "\n",
    "def read_csv_from_s3(bucket: str, path: str, file_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Reads a CSV file from an S3 bucket and returns it as a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bucket : str\n",
    "        The name of the S3 bucket.\n",
    "    key : str\n",
    "        The key (path) of the CSV file in the S3 bucket.\n",
    "    file_name: str\n",
    "        The name of the file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame containing the data from the CSV file.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "\n",
    "    full_path = f'{path}{file_name}'\n",
    "\n",
    "    object = s3.get_object(Bucket=bucket, Key=full_path)\n",
    "    object = object['Body'].read().decode('utf-8')\n",
    "    output_df = pd.read_csv(StringIO(object))\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "def read_json_from_s3(bucket: str, file_key: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a JSON file from an S3 bucket and returns its contents as a pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "        bucket (str): Name of the S3 bucket.\n",
    "        \n",
    "        file_key (str): Key (path) to the JSON file in the bucket.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the JSON data.\n",
    "    \"\"\"\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    response = s3.get_object(Bucket = bucket, Key = file_key)\n",
    "    content = response['Body']\n",
    "    weather_data = json.loads(content.read())\n",
    "    \n",
    "    df_weather_data = pd.DataFrame(weather_data)\n",
    "\n",
    "    return df_weather_data\n",
    "\n",
    "def update_taxi_trips_with_master_data(taxi_trips: pd.DataFrame, payment_type_master: pd.DataFrame, company_master: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Update the taxi trips DataFrame with information from master data tables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    taxi_trips : pd.DataFrame\n",
    "        A DataFrame containing taxi trip records, including 'payment_type' and 'company' columns.\n",
    "    payment_type_master : pd.DataFrame\n",
    "        Payment type master table.\n",
    "    company_master : pd.DataFrame\n",
    "        Company master table.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with the original trip data enriched with information from \n",
    "        the payment type and company master data.\n",
    "\n",
    "    \"\"\"\n",
    "    taxi_trips_id = taxi_trips.merge(payment_type_master, on= 'payment_type')\n",
    "    taxi_trips_id = taxi_trips_id.merge(company_master, on= 'company')\n",
    "    taxi_trips_id.drop([\"payment_type\", \"company\"], axis=1, inplace=True)\n",
    "    return taxi_trips_id\n",
    "\n",
    "def upload_dataframe_to_s3(bucket: str, dataframe: pd.DataFrame, path: str) -> None:\n",
    "    \"\"\"\n",
    "    Uploads a dataframe to S3 as a CSV file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bucket : str\n",
    "        Name of the S3 bucket where we want to store the files.\n",
    "\n",
    "    dataframe : pd.DataFrame\n",
    "        The dataframe to be uploaded.\n",
    "\n",
    "    path : str\n",
    "        Path within the bucket to upload the files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    buffer = StringIO()\n",
    "    dataframe.to_csv(buffer, index=False)\n",
    "    df_content = buffer.getvalue()\n",
    "    s3.put_object(Bucket=bucket, Key=path, Body=df_content)\n",
    "\n",
    "def upload_master_data_to_s3(bucket: str, path: str, file_type: str, dataframe: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Uploads master data (payment_type or company) to S3. Copy and uploads the new version.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bucket : str\n",
    "        The name of the S3 bucket where the file will be stored.\n",
    "\n",
    "    path : str\n",
    "        The path within the S3 bucket where the file will be uploaded.\n",
    "\n",
    "    file_type : str\n",
    "        The type of master data to upload.\n",
    "\n",
    "    dataframe : pd.DataFrame\n",
    "        The DataFrame containing the data to be uploaded.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    # Copy the master files\n",
    "    master_file_path = f\"{path}{file_type}_master.csv\"\n",
    "    previous_master_file_path = f\"transformed_data/master_table_previous_version/{file_type}_master_previous_version.csv\"\n",
    "    s3.copy_object(\n",
    "        Bucket=bucket,\n",
    "        CopySource={\"Bucket\": bucket, \"Key\": master_file_path},\n",
    "        Key=previous_master_file_path\n",
    "    )\n",
    "    # Create the new master file\n",
    "    upload_dataframe_to_s3(bucket = bucket, dataframe=dataframe, path=master_file_path)\n",
    "\n",
    "def uplod_and_move_file_on_s3(\n",
    "        dataframe: pd.DataFrame, \n",
    "        datetime_col: str, \n",
    "        bucket: str, \n",
    "        file_type: str, \n",
    "        filename: str,\n",
    "        source_path: str,\n",
    "        target_path_raw: str,\n",
    "        target_path_transformed: str\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Uploads a DataFrame to S3, and moves the original file from the raw path to the transformed path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : pd.DataFrame\n",
    "        The DataFrame to upload to S3.\n",
    "\n",
    "    datetime_col : str\n",
    "        Name of the column in the DataFrame containing the datetime values.\n",
    "\n",
    "    bucket : str\n",
    "        Name of the S3 bucket.\n",
    "\n",
    "    file_type : str\n",
    "        A string to identify the file type.\n",
    "\n",
    "    filename : str\n",
    "        The original filename in the raw S3 path.\n",
    "\n",
    "    source_path : str\n",
    "        The S3 path (prefix) where the original file is currently stored.\n",
    "\n",
    "    target_path_raw : str\n",
    "        The S3 path where the original file will be moved from.\n",
    "\n",
    "    target_path_transformed : str\n",
    "        The S3 path where the transformed (new) file will be uploaded.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    \n",
    "    formatted_date = dataframe[datetime_col].iloc[0].strftime(\"%Y-%m-%d\")\n",
    "    new_path_with_filename = f\"{target_path_transformed}{file_type}_{formatted_date}.csv\"\n",
    "    \n",
    "    upload_dataframe_to_s3(bucket=bucket, dataframe=dataframe, path=new_path_with_filename)\n",
    "    \n",
    "    s3.copy_object(\n",
    "        Bucket=bucket,\n",
    "        CopySource={\"Bucket\": bucket, \"Key\":f\"{source_path}{filename}\"},\n",
    "        Key=f\"{target_path_raw}{filename}\"\n",
    "    )\n",
    "    \n",
    "    s3.delete_object(Bucket=bucket, Key=f\"{source_path}{filename}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main function\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    bucket = 'de-chicago-taxi'\n",
    "    raw_weather_folder = 'raw_data/to_processed/weather_data/'\n",
    "    raw_taxi_folder = 'raw_data/to_processed/taxi_data/'\n",
    "    target_taxi_folder = 'raw_data/processed/taxi_data/'\n",
    "    target_weather_folder = 'raw_data/processed/weather_data/'\n",
    "    transformed_taxi_folder = 'transformed_data/taxi_trips/'\n",
    "    transformed_weather_folder = 'transformed_data/weather/'\n",
    "    file_key = 'raw_data/to_processed/test_data/weather_raw_2025-02-03.json'\n",
    "    \n",
    "    path_payment_type_master = 'transformed_data/payment_type/'\n",
    "    path_company_master = 'transformed_data/company/'\n",
    "    payment_type_master_file_name = 'payment_type_master.csv'\n",
    "    company_master_file_name = 'company_master.csv'\n",
    "    \n",
    "    # Master data loading\n",
    "    company_master = read_csv_from_s3(bucket, path_company_master, company_master_file_name)\n",
    "    payment_type_master = read_csv_from_s3(bucket, path_payment_type_master, payment_type_master_file_name )\n",
    "    \n",
    "    # Read_json_from_s3 function\n",
    "    json_weather = read_json_from_s3(bucket= bucket, file_key=file_key)\n",
    "    print(json_weather)\n",
    "\n",
    "    # Taxi data transformation and loading\n",
    "    for file in s3.list_objects(Bucket=bucket, Prefix=raw_taxi_folder)['Contents']:\n",
    "        taxi_key = file['Key']\n",
    "        \n",
    "        if taxi_key.split('/')[-1].strip() != '':\n",
    "            if taxi_key.endswith('.json'):\n",
    "\n",
    "                file_name = taxi_key.split('/')[-1]\n",
    "\n",
    "            \n",
    "            \n",
    "                response = s3.get_object(Bucket=bucket, Key=taxi_key)\n",
    "                content = response['Body']\n",
    "                taxi_data_json = json.loads(content.read())\n",
    "                print(taxi_key)\n",
    "                taxi_data_raw_df = pd.DataFrame(taxi_data_json)\n",
    "                taxi_trips_transformed = taxi_trips_transformation(taxi_data_raw_df)\n",
    "\n",
    "            \n",
    "                # Update master data\n",
    "                company_master_updated = update_master(taxi_trips_transformed, company_master, 'company_id', 'company')\n",
    "                payment_type_master_updated = update_master(taxi_trips_transformed, payment_type_master, 'payment_type_id', 'payment_type')\n",
    "                \n",
    "                # Update taxi trips with master data\n",
    "                taxi_trips = update_taxi_trips_with_master_data(taxi_trips= taxi_trips_transformed, payment_type_master= payment_type_master_updated, company_master=company_master_updated)\n",
    "            \n",
    "                uplod_and_move_file_on_s3(\n",
    "                    dataframe= taxi_trips, \n",
    "                    datetime_col= 'datetime_for_weather', \n",
    "                    bucket= bucket, \n",
    "                    file_type= 'taxi', \n",
    "                    filename= file_name,\n",
    "                    source_path= raw_taxi_folder ,\n",
    "                    target_path_raw= target_taxi_folder,\n",
    "                    target_path_transformed= transformed_taxi_folder\n",
    "                )\n",
    "\n",
    "                print('Taxi trips transformed and moved')\n",
    "                # Upload master data to S3 \n",
    "                upload_master_data_to_s3(bucket=bucket, path= path_company_master, file_type= 'company', dataframe=company_master_updated)\n",
    "            \n",
    "                upload_master_data_to_s3(bucket= bucket, path= path_payment_type_master, file_type= 'payment_type', dataframe= payment_type_master_updated)\n",
    "            \n",
    "\n",
    "    # Weather data transformation and loading\n",
    "    for file in s3.list_objects(Bucket=bucket, Prefix=raw_weather_folder)['Contents']:\n",
    "        weather_key = file['Key']\n",
    "\n",
    "        if weather_key.split('/')[-1].strip() != '':\n",
    "            if weather_key.split('.')[1] == 'json':\n",
    "                \n",
    "                file_name = weather_key.split('/')[-1]\n",
    "                \n",
    "                response = s3.get_object(Bucket=bucket, Key=weather_key)\n",
    "                content = response['Body']\n",
    "                weather_data_json = json.loads(content.read())\n",
    "\n",
    "                weather_data_df = transform_weather_data(weather_data_json)\n",
    "\n",
    "                \n",
    "                uplod_and_move_file_on_s3(\n",
    "                    dataframe= weather_data_df, \n",
    "                    datetime_col= 'datetime', \n",
    "                    bucket= bucket, \n",
    "                    file_type= 'weather', \n",
    "                    filename= file_name,\n",
    "                    source_path= raw_weather_folder ,\n",
    "                    target_path_raw= target_weather_folder,\n",
    "                    target_path_transformed= transformed_weather_folder\n",
    "                    )\n",
    "\n",
    "                print('weather data transformed and moved')\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
